\pagenumbering{arabic}

# Introduction

## Motivation

Across many fields, decision makers face the problem of assessing and mitigating the risk associated with rare, extreme events. For instance, institutions seek accurate models of financial losses to design strategies to reduce their exposure, while an understanding of rare environmental phenomena, such as floods or hurricanes, guides the development of resilient defence infrastructure and public safety measures. Extreme value theory (EVT) provides a rigorous probabilistic framework for analysing the stochastic behaviour of such events. In particular, EVT is underpinned by asymptotic arguments that allow the probability law to be extrapolated beyond the maxima of the observed data. In principle, one can estimate the risk of unprecedented occurrences (i.e. events of a magnitude that has not been observed previously). Naively assuming that such events are impossible, as one might conclude from an empirical approach, could have catastrophic consequences. Equally, overestimating the probability of such events leads to an inefficient allocation of resources. Effective risk management therefore involves evaluating the trade-off between events' impacts and their probabilities. The latter aspect falls under the remit of EVT and, by extension, this thesis.

The concept of extremal dependence is central to assessing the risk of joint extreme events involving several different variables or interacting systems. In many practical scenarios, extreme events do not occur in isolation but are fundamentally interconnected. Simultaneous extreme rainfall across multiple regions can lead to compounded flood risks; the co-occurrence of extreme market crashes in different sectors can exacerbate market instability. Accounting for these associations is a critical element of risk modelling. For example, suppose a fund manager oversees a portfolio of $d$ stocks and let $X_i$ denote the daily negative log-return of the $i$th stock for $i=1,\ldots,d$. The Value-at-Risk (VaR) is a popular tool for assessing the portfolio risk in terms of total losses over a one-day horizon, defined as the $100(1-\alpha)\%$ quantile of $L=\sum_{i=1}^d w_iX_i$, where $w_i\in(0,1]$ represents the relative weight of stock $i$ in the portfolio and $\alpha\in(0,1)$ is a prescribed confidence level [@yuenUpperBoundsValueatrisk2014]. If one assumes that extreme losses behave independently then the VaR figure might appear reassuringly small. However, financial crises or sudden macroeconomic shocks often cause simultaneous and correlated extreme losses across multiple stocks due to shared exposure to systemic risk factors and herd behaviour among investors. The dependence structure of $(X_1,\ldots,X_d)$ influences the quantile behaviour of $L$ and consequently the Value-at-Risk. Portfolio diversification aims to alleviate this risk by balancing exposure across different asset classes and markets that are deemed to be less correlated. 

Modelling extremal dependence becomes especially challenging when the number of variables under consideration is large. High-dimensional extremal dependence arises in applications such as environmental science, where a climatic variable is studied across multiple sites in a spatial domain. In such settings, the curse of dimensionality, the complexity of the dependence structure, and the inherent scarcity of relevant data points all impede efforts to model the probabilistic structure of the joint tail. Advancing methods to analyse extremal dependence in high dimensions is critical for addressing real-world, large-scale problems. This is the overarching goal of this thesis. 

One particularly useful tool for understanding high-dimensional extremal dependence is the tail pairwise dependence matrix (TPDM) developed by @cooleyDecompositionsDependenceHighdimensional2019. The TPDM provides a compact summary of extremal dependence among pairs of variables by quantifying their joint tail behaviour, similar to a covariance/correlation matrix in non-extreme statistics. This facilitates exploratory analyses of dependence patterns and underpins a whole host of modern techniques for analysing multivariate extremes, including dimension reduction methods [@cooleyDecompositionsDependenceHighdimensional2019; @dreesPrincipalComponentAnalysis2021; @fomichovSphericalClusteringDetection2023; @richardsModernExtremeValue2024] and inference for parametric models [@fixSimultaneousAutoregressiveModels2021; @kirilioukEstimatingProbabilitiesMultivariate2022]. By leveraging the TPDM, it becomes possible to develop efficient and scalable methods for modelling extremal dependence, thereby addressing the challenges posed by high-dimensional settings while maintaining computational feasibility. This thesis proposes new applications of this matrix, growing the toolbox of TPDM-based techniques for analysing multivariate extremes. 

## Thesis aims and outline

The primary aim of this thesis is to develop novel statistical applications of the TPDM. Our strategy for identifying new applications is two-fold. First, we observe that the TPDM is useful for overcoming the curse of dimensionality and compactly summarising the dependence structure. Thus, we seek out opportunities where these properties might be exploited. Second, we draw on the fact that the TPDM may be cast as an analogue to the correlation/covariance matrix in non-extremes settings. The covariance matrix is ubiquitous in multivariate statistics, underpinning many powerful methods, such as principal components analysis and linear discriminant analysis. Thus, whenever one finds an application of the covariance matrix, one can consider whether an analogous method might make sense for the TPDM and extremes. The rest of this section outlines the structure of the thesis and summarises its key contributions.

@sec-background provides a detailed overview of univariate and multivariate extreme value statistics, before introducing the main protagonist of the thesis: the TPDM. We provide an overview of its mathematical properties, which will be called upon throughout the later chapters of the thesis. Next, we survey the TPDM-related literature, detailing its existing applications with a focus on principal components analysis and max-linear models. By acquainting the reader with these methods, we can build upon them in later chapters and highlight gaps they fail to address. Finally, we illustrate a known deficiency of the standard TPDM estimator, whereby it overestimates the dependence between weakly correlated variables. While the bias issue is not of direct interest until @sec-shrinkage-tpdm, issues stemming from it will be pointed out throughout the thesis.

@sec-changing-ext-dep presents a statistical procedure to test for temporal non-stationarity in the extremal dependence structure of a (potentially high-dimensional) random vector indexed by time. This is motivated by the need to validate the ubiquitous assumption that extreme observations are identically distributed over time. We define a time-dependent extension of the TPDM and establish its basic properties. Next, we derive the asymptotic null distribution of functionals of this object, which we use to test for deviations over time. In contrast to existing methods, our test scales to high dimensions and has a much lower computational overhead because it is rooted in the TPDM. The performance of the test across a range of scenarios is illustrated using simulation experiments. An application to Red Sea surface temperature data corroborates the theory that the region is undergoing changes driven by climate change.

@sec-compositional explores connections between multivariate extremes and compositional data analysis (CoDA). Observing that both disciplines boil down to analysing distributions on the simplex, we argue that off-the-shelf CoDA tools are an underutilised resource among the extremes community. Our simulation experiments show how compositional PCA may yield more efficient and interpretable dimension reduction compared to the TPDM-based method of @dreesPrincipalComponentAnalysis2021. We also investigate the use of CoDA techniques for binary classification of extreme events [@jalalzaiBinaryClassificationExtreme2018]. Our results show that accounting for the geometry of the sample space (i.e. the simplex) can enhance predictive performance significantly.

@sec-eva-data-challenge summarises the techniques employed by team 'Uniofbathtopia' as part of the data competition organised for the 13th International Conference on Extreme Value Analysis (EVA2023). The competition comprised four sub-challenges focussing on a multitude of aspects from univariate and multivariate EVT. Additional information and context are provided in @sec-eva-preliminary and in the editorial [@rohrbeckEditorialEVAConference2023]. @sec-eva-abstract onwards are taken from the paper *Extreme value statistics for analysing simulated environmental extremes*, which I co-authored with H. Elsom and which details our methods for each sub-challenge. @sec-eva-univariate, researched and written by H. Elsom, pertains to the univariate sub-challenges (Challenges 1 and 2). @sec-eva-multivariate concerns the multivariate tasks (Challenges 3 and 4) and was researched and written by myself. In Challenge 3 (@sec-eva-c3), we combine sparse simplex projections with a flexible parametric model to obtain probability estimates for joint extreme events involving different combinations of variables. Our methodology exhibits state-of-the-art performance, topping the rankings for this sub-challenge. For Challenge 4 (@sec-eva-c4) we combine clustering and completely positive factorisations of the TPDM [@kirilioukEstimatingProbabilitiesMultivariate2022] to estimate exceedingly rare events in high dimensions. Our post-hoc analysis reveals that unreliable TPDM estimation hindered our performance, prompting us to address this issue in the following chapter.

In @sec-shrinkage-tpdm we consider ways of addressing a well-known bias of the empirical TPDM, whereby it tends to overestimate the dependence between weakly correlated variables. We employ regularisation methods such as thresholding and linear shrinkage to generate classes of flexible estimators. We devise the first data-driven method for selecting the regularisation parameter. Our estimator is illustrated using a series of simulated examples and may be readily incorporated into existing/future modelling frameworks.

The thesis concludes with a summary and discussion of future research directions in @sec-conclusion. 

The code required to reproduce all the results contained in this thesis (including figures and tables) has been made available in a GitHub repository at [https://github.com/pawleymatthew/Extensions-And-Applications-of-TPDM](https://github.com/pawleymatthew/Extensions-And-Applications-of-TPDM).

