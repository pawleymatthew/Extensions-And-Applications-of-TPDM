# Supplementary Material for @sec-compositional {#sec-app-compositional-additional-results}

```{r appendix-compositional-load-packages}
#| include: false
library(tidyverse)
library(tidyr)
library(magrittr)
library(scales)
library(ggh4x)
library(ggpubr)
library(colorspace)
library(pbapply)
library(kableExtra)
library(reshape2)
library(compositions)
library(Ternary)
library(SpatialExtremes)
library(caret)
library(lattice)

options(dplyr.summarise.inform = FALSE)
options(knitr.kable.NA = "")
```

```{r appendix-compositional-source-functions}
#| include: false
sapply(list.files(path = "R/compositional", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
sapply(list.files(path = "R/general", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
```

```{r make-fig-sim-pca-max-linear-loss-large-n}
#| label: fig-sim-pca-max-linear-loss-large-n
#| fig-cap: "Performance of CoDA-PCA and DS-PCA for the trivariate max-linear data. Results are based on 50 repeated simulations from the MS and TL processes with $n=50,000$ and $k/n=0.01$. Top row: the Aitchison reconstruction error \\eqref{eq-L-aitchison} and Euclidean reconstruction error \\eqref{eq-L-euclidean} against the number of retained components. Reconstruction errors are obtained from 10,000 samples from the true angular measure. Bottom row: estimates of $p_{\\min}$ (left) and $p_{\\max}$ (left) based on \\eqref{eq-prob-min-max-pca} against $p$, the rank of the principal subspace."
#| fig-scap: "PCA performance metrics for trivariate max-linear data ($n=50,000$)."
#| fig-height: 6
#| message: false
#| warning: false

res <- readRDS(file = file.path("scripts", "compositional", "results", "sim-pca-az.RDS")) %>%
  filter(n_train == 50000, k_frac == 0.01)

p1 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Transformed-linear",
                                  .default = "Max-stable")) %>%
  mutate(pca_method = case_when(pca_method == "coda" ~ "CoDA",
                                .default = "DS")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  pivot_longer(cols = c(test_loss_aitchison, test_loss_euclidean), names_to = "loss_type", values_to = "test_loss") %>%
  filter(loss_type == "test_loss_aitchison") %>%
  ggplot(aes(x = interaction(as.factor(n_pcs), pca_method), y = test_loss)) +
  geom_boxplot() +
  facet_grid(. ~ maxlin_model) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05)), breaks = breaks_extended(n = 4)) +
  scale_x_discrete(guide = "axis_nested") +
  labs(fill = "PCA method",
       x = "",
       y = "Aitchison reconstruction error") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light() +
  theme(ggh4x.axis.nestline = element_line(linetype = 2))

p2 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Transformed-linear",
                                  .default = "Max-stable")) %>%
  mutate(pca_method = case_when(pca_method == "coda" ~ "CoDA",
                                .default = "DS")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  pivot_longer(cols = c(test_loss_aitchison, test_loss_euclidean), names_to = "loss_type", values_to = "test_loss") %>%
  filter(loss_type == "test_loss_euclidean") %>%
  ggplot(aes(x = interaction(as.factor(n_pcs), pca_method), y = test_loss)) +
  geom_boxplot() +
  facet_grid(. ~ maxlin_model) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05)), breaks = breaks_extended(n = 4)) +
  scale_x_discrete(guide = "axis_nested") +
  labs(fill = "PCA method",
       x = "",
       y = "Euclidean reconstruction error") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light() +
  theme(ggh4x.axis.nestline = element_line(linetype = 2))

p3 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Transformed-linear",
                                  .default = "Max-stable")) %>%
  mutate(pca_method = case_when(pca_method == "coda" ~ "CoDA",
                                .default = "DS")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  ggplot(aes(x = interaction(as.factor(n_pcs), pca_method), y = p_min_hat / 3)) +
  geom_boxplot() +
  facet_grid(. ~ maxlin_model) +
  geom_hline(aes(yintercept = p_min / 3), colour = "blue", linetype = "dashed") +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = breaks_extended(n = 4)) +
  scale_x_discrete(guide = "axis_nested") +
  labs(fill = "PCA method",
       x = "",
       y = expression(hat(p)[min])) +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light() +
  theme(ggh4x.axis.nestline = element_line(linetype = 2))

p4 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Transformed-linear",
                                  .default = "Max-stable")) %>%
  mutate(pca_method = case_when(pca_method == "coda" ~ "CoDA",
                                .default = "DS")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  ggplot(aes(x = interaction(as.factor(n_pcs), pca_method), y = p_max_hat / 3)) +
  geom_boxplot() +
  facet_grid(. ~ maxlin_model) +
  geom_hline(aes(yintercept = p_max / 3), colour = "blue", linetype = "dashed") +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05)), breaks = breaks_extended(n = 4)) +
  scale_x_discrete(guide = "axis_nested") +
  labs(fill = "PCA method",
       x = "",
       y = expression(hat(p)[max])) +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light() +
  theme(ggh4x.axis.nestline = element_line(linetype = 2))

ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2)
```

```{r make-fig-sim-pca-hr-metrics-pmax}
#| label: fig-sim-pca-hr-metrics-pmax
#| fig-cap: "Estimates of $p_{\\max}$ against the rank of the CoDA- or DS-PCA reconstruction for the four Hüsler-Reiss models. Results are based on 50 repeated simulations."
#| fig-scap: "Estimates of $p_{\\max}$ for the Hüsler-Reiss models."
#| fig-height: 7

res <- bind_rows(readRDS(file = file.path("scripts", "compositional", "results", "sim-pca-hr-threedim.RDS")),
                 readRDS(file = file.path("scripts", "compositional", "results", "sim-pca-hr-highdim.RDS"))) %>%
  mutate(vario_seed_index = case_when(is.na(vario_seed_index) ~ 4, .default = vario_seed_index))

res %>%
  mutate(d = case_when(vario_seed_index <= 3 ~ 3, .default = 10)) %>%
  mutate(pca_method = case_when(pca_method == "coda" ~ "CoDA",
                                .default = "DS")) %>%
  mutate(vario_seed_index = paste0("Lambda[", vario_seed_index, "]")) %>%
  ggplot(aes(x = interaction(as.factor(n_pcs), pca_method), y = p_max_hat / d)) +
  geom_boxplot() +
  geom_hline(aes(yintercept = p_max), colour = "blue", linetype = "dashed") +
  facet_wrap(. ~ as.factor(vario_seed_index), scales = "free", labeller = label_parsed) +
  scale_x_discrete(guide = "axis_nested") +
  labs(x = "",
       y = expression(hat(p)[max])) +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light() +
  theme(ggh4x.axis.nestline = element_line(linetype = 2))
```

```{r make-fig-sim-classification-train-test-risk}
#| label: fig-sim-classification-train-test-risk
#| fig-cap: "Median of the empirical classification risk (based on $k$ extremal angles) and the true asymptotic classification risk (based on the 'test' set of samples from $H$) against the transformation parameter $\\alpha$. Based on the experiments described in @sec-compositional-classification-experiments."
#| fig-scap: "Comparison of the empirical and asymptotic classification risks."
#| fig-height: 6

# plot the training risk (based on k largest training angles) versus risk based on samples from H

readRDS(file = file.path("scripts", "compositional", "results", "classification-sim-results-knn-svm-rf.RDS")) %>%
  mutate(nice_model = case_when(nice_model == "Symmetric" ~ "SL",
                                nice_model == "Bi" ~ "BL",
                                nice_model == "Negative" ~ "NL",)) %>%
  mutate(classifier = case_when(classifier == "knn" ~ 'k * "-NN" * (alpha)',
                                classifier == "svm" ~ '"SVM" * (alpha)',
                                classifier == "rf" ~ '"RF" * (alpha)')) %>%
  mutate(param0 = paste0("vartheta[-1] == ", param0),
         param1_frac = paste0("vartheta[1]/vartheta[-1] == ", param1_frac)) %>%
  pivot_longer(cols = c("train_error", "test_error"), names_to = "error_type", values_to = "error") %>%
  ggplot(aes(x = alpha, y = error, colour = classifier,  linetype = error_type)) +
  stat_summary(geom = "line", fun = median) +
  facet_nested_wrap(param1_frac ~ nice_model, scales = "free", labeller = label_parsed, nrow = 2,
                    nest_line = element_line(colour = "white")) +
  scale_x_continuous(limits = c(0, 1), expand = c(0.01, 0.01), breaks = breaks_pretty(n = 5)) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.05)), breaks = breaks_pretty(n = 4), labels = label_percent()) +
  scale_colour_manual(values = c("red", "blue", "darkgreen"), labels = parse_format()) +
  scale_fill_manual(values = c("red", "blue", "darkgreen"), labels = parse_format()) +
  scale_linetype_manual(values = 1:2, labels = c("Asymptotic risk", "Empirical risk")) +
  xlab(expression(alpha)) +
  ylab("Risk") +
  labs(linetype = "Risk type", colour = "Classifier") +
  theme_light() +
  theme(legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank())
```
