```{r appendix-compositional-load-packages}
#| include: false
library(tidyverse)
library(tidyr)
library(magrittr)
library(scales)
library(ggh4x)
library(ggpubr)
library(colorspace)
library(pbapply)
library(kableExtra)
library(reshape2)
library(compositions)
library(Ternary)
library(SpatialExtremes)
library(caret)
library(lattice)

options(dplyr.summarise.inform = FALSE)
options(knitr.kable.NA = "")
```

```{r appendix-compositional-source-functions}
#| include: false
sapply(list.files(path = "R/compositional", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
sapply(list.files(path = "R/general", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
```

# Max-linear example with other combinations of $n$ and $k$

```{r make-fig-sim-pca-max-linear-loss-full}
#| label: fig-sim-pca-max-linear-loss-full
#| fig-cap: "PCA performance metrics based on trivariate max-linear data."
#| fig-scap: "PCA performance metrics based on trivariate max-linear data."
#| fig-height: 6

res <- readRDS(file = file.path("scripts", "compositional", "results", "sim-pca-az.RDS"))

p1 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Regular variation",
                                  .default = "Max-stable")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  pivot_longer(cols = c(test_loss_aitchison, test_loss_euclidean), names_to = "loss_type", values_to = "test_loss") %>%
  filter(loss_type == "test_loss_aitchison") %>%
  ggplot(aes(x = maxlin_model, y = test_loss, fill = pca_method, linetype = as.factor(n_pcs))) +
  geom_boxplot() +
  facet_grid(`k/n` ~ `n`, labeller = purrr::partial(label_both, sep = " = ")) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05))) +
  scale_fill_manual(labels = c("CoDA", "D&S"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("1", "2"), values = 1:2) +
  scale_x_discrete(labels = c("MS", "RV")) +
  labs(fill = "PCA method",
       linetype = "Number of PCs",
       x = "Generative model",
       y = "MSRE (Aitchison)") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light()

p2 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Regular variation",
                                  .default = "Max-stable")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  pivot_longer(cols = c(test_loss_aitchison, test_loss_euclidean), names_to = "loss_type", values_to = "test_loss") %>%
  filter(loss_type == "test_loss_euclidean") %>%
  ggplot(aes(x = maxlin_model, y = test_loss, fill = pca_method, linetype = as.factor(n_pcs))) +
  geom_boxplot() +
  facet_grid(`k/n` ~ `n`, labeller = purrr::partial(label_both, sep = " = ")) +
  scale_y_continuous(limits = c(0, NA), expand = expansion(mult = c(0, 0.05))) +
  scale_fill_manual(labels = c("CoDA", "D&S"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("1", "2"), values = 1:2) +
  scale_x_discrete(labels = c("MS", "RV")) +
  labs(fill = "PCA method",
       linetype = "Number of PCs",
       x = "Generative model",
       y = "MSRE (Euclidean)") +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light()

p3 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Regular variation",
                                  .default = "Max-stable")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  ggplot(aes(x = maxlin_model, y = p_min_hat / 3, fill = pca_method, linetype = as.factor(n_pcs))) +
  geom_boxplot() +
  geom_hline(aes(yintercept = p_min / 3), colour = "black", linetype = "dashed") +
  facet_grid(`k/n` ~ `n`, labeller = purrr::partial(label_both, sep = " = ")) +
  scale_fill_manual(labels = c("CoDA", "D&S"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("1", "2"), values = 1:2) +
  scale_x_discrete(labels = c("MS", "RV")) +
  labs(fill = "PCA method",
       linetype = "Number of PCs",
       x = "Generative model",
       y = expression(lim(P(min(bold(X)) > u ~ "|" ~ "||"* bold(X) * "||"[1] > u), u %->% infinity))) +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light()

p4 <- res %>%
  mutate(maxlin_model = case_when(maxlin_model == "cooley" ~ "Regular variation",
                                  .default = "Max-stable")) %>%
  mutate(n_train = as.factor(n_train), k_frac = as.factor(label_percent()(k_frac))) %>%
  rename('n' = n_train, 'k/n' = k_frac) %>%
  ggplot(aes(x = maxlin_model, y = p_max_hat / 3, fill = pca_method, linetype = as.factor(n_pcs))) +
  geom_boxplot() +
  geom_hline(aes(yintercept = p_max / 3), colour = "black", linetype = "dashed") +
  facet_grid(`k/n` ~ `n`, labeller = purrr::partial(label_both, sep = " = ")) +
  scale_fill_manual(labels = c("CoDA", "D&S"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("1", "2"), values = 1:2) +
  scale_x_discrete(labels = c("MS", "RV")) +
  labs(fill = "PCA method",
       linetype = "Number of PCs",
       x = "Generative model",
       y = expression(lim(P(max(bold(X)) > u ~ "|" ~ "||"* bold(X) * "||"[1] > u), u %->% infinity))) +
  theme(panel.grid.minor = element_blank(),
        panel.grid.major = element_blank()) +
  theme_light()

ggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2, legend = "top", common.legend = TRUE)
```

### Computational details regarding the $k$-NN($\alpha$), $\alpha$-SVM and $\alpha$-RF classifiers

*List the hyperparameters of each method, describe what they mean, list the ranges of values used, and give any relevant computational details. Refer to $\texttt{Compositional}$ and $\texttt{CompositionalML}$ packages.*

### Training risk and test risk for classification

```{r make-fig-sim-classification-train-test-risk}
#| label: fig-sim-classification-train-test-risk
#| fig-cap: "Blah."
#| fig-scap: "Blah."
#| fig-height: 6

readRDS(file = file.path("scripts", "compositional", "results", "classification-sim-results-knn-svm-rf.RDS")) %>%
  mutate(nice_model = case_when(nice_model == "Symmetric" ~ "SL",
                                nice_model == "Bi" ~ "BL",
                                nice_model == "Negative" ~ "NL",)) %>%
  mutate(classifier = case_when(classifier == "knn" ~ 'k * "-NN" * (alpha)',
                                classifier == "svm" ~ '"SVM" * (alpha)',
                                classifier == "rf" ~ '"RF" * (alpha)')) %>%
  mutate(param0 = paste0("vartheta[-1] == ", param0),
         param1_frac = paste0("vartheta[1]/vartheta[-1] == ", param1_frac)) %>%
  pivot_longer(cols = c("train_error", "test_error"), names_to = "error_type", values_to = "error") %>%
  ggplot(aes(x = alpha, y = error, colour = classifier,  linetype = error_type)) +
  stat_summary(geom = "line", fun = median) +
  facet_nested_wrap(param1_frac ~ nice_model, scales = "free", labeller = label_parsed, nrow = 2,
                    nest_line = element_line(colour = "white")) +
  scale_x_continuous(limits = c(0, 1), expand = c(0.01, 0.01), breaks = breaks_pretty(n = 5)) +
  scale_y_continuous(expand = expansion(mult = c(0.05, 0.05)), breaks = breaks_pretty(n = 4), labels = label_percent()) +
  scale_colour_manual(values = c("red", "blue", "darkgreen"), labels = parse_format()) +
  scale_fill_manual(values = c("red", "blue", "darkgreen"), labels = parse_format()) +
  scale_linetype_manual(values = 1:2, labels = c("Asymptotic (test set)", "Empirical at level t (train set)")) +
  xlab(expression(alpha)) +
  ylab("Risk") +
  labs(linetype = "Risk type", colour = "Classifier") +
  theme_light() +
  theme(legend.position = "top",
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank())
```
