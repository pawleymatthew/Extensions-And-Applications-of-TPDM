# Supplementary Material for @sec-changing-ext-dep

```{r appendix-changing-ext-dep-load-packages}
#| include: false
library(tidyverse)
library(tidyr)
library(magrittr)
library(SimCop)
library(pracma)
library(expm)
library(sn)
library(scales)
library(ggh4x)
library(CPAT)
library(maps)
library(patchwork)
library(ggpubr)
library(colorspace)
library(pbapply)
library(kableExtra)
library(reshape2)
library(e1071) # simulate Brownian bridge
library(tictoc)

options(dplyr.summarise.inform = FALSE)
options(knitr.kable.NA = "")
```


```{r appendix-changing-ext-dep-source-functions}
#| include: false
sapply(list.files(path = "R/changing-ext-dep", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
sapply(list.files(path = "R/general", pattern = "*.R", full.names = TRUE, recursive = TRUE), source)
bb_L2 <- readRDS("scripts/changing-ext-dep/results/bb_L2.RDS")
```

## Overview of @dreesStatisticalInferenceChanging2023 {#sec-app-changing-ext-dep-drees}

This appendix provides a concise overview of @dreesStatisticalInferenceChanging2023. The paper is rather technical, so we aim to provide a high-level summary allowing the reader to better understand the results presented in @sec-changing-ext-dep. 

@dreesStatisticalInferenceChanging2023 test the hypotheses \eqref{eq-changing-ext-dep-null-hyp} and \eqref{eq-changing-ext-dep-alt-hyp} by detecting changes in the full angular measure, rather than a bivariate summary like the TPDM. Let $\mathcal{A}$ be a large family of Borel subsets of $\mathbb{S}_{+(2)}^{d-1}$. Then, suitably rescaled versions of the stochastic processes
\begin{equation}\label{eq-drees-test-process}
\left\lbrace\int_0^t \hat{H}(A;s)\,\dee s - t \int_0^1 \hat{H}(A;s)\,\dee s : t\in[0,1]\right\rbrace, \qquad A\in\mathcal{A},
\end{equation}
converge to a mean-zero Gaussian process whose covariance function depends on $H$. KS- and CM-type test statistics are defined analogously to \eqref{eq-test-stat-ks} and \eqref{eq-test-stat-cm} in terms of this Gaussian process. However, since the covariance function depends on the true angular measure, critical values must be obtained by simulation each time (except in the bivariate case, provided $\mathcal{A}$ satisfies certain properties). The null is rejected if any paths in \eqref{eq-drees-test-process} deviate from what would typically occur under the null. 
If $\mathcal{A}$ is sufficiently rich, then very subtle dependence changes may be revealed. However, as the dimension $d$ increases the family of sets grows rapidly, typically $|\mathcal{A}|=\mathcal{O}(2^d)$. Consequently, computing the critical values become prohibitively intensive and the convergence $\hat{H}(A;t)\to H(A;t)$ of the non-parametric estimators is too slow to yield reliable results. Thus, their method is primarily intended for the bivariate setting and is restricted to $d\leq 5$ in practice. Fundamentally, the issue is that one needs to estimate a high-dimensional measure using a very small number of observations (the subset of extreme observations lying within a small temporal neighbourhood). Our approach mitigates this issue by concentrating on $\mathcal{O}(d^2)$ bivariate summaries of tail dependence instead of the full dependence structure.

## Additional figures {#sec-app-changing-ext-dep-additional-results}

```{r load-sim-results-appendix}
sim_results <- list(file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed1.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed2.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed3.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed4.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed5.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed6.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed7.RDS"),
                    file.path("scripts", "changing-ext-dep", "results", "sim-test-results-seed8.RDS")) %>%
  lapply(readRDS) %>%
  bind_rows()
```

```{r make-fig-bivariate-power-vary-b-k}
#| label: fig-bivariate-power-vary-b-k
#| fig-cap: "Empirical power (%) as a function of the dependence parameter $\\vartheta_1$ for different combinations of tuning parameters $b$ and $k$. Based on 1000 simulations with $n=2,500$ and $d=2$. For the SL and HR models, $\\vartheta_0=2$ and $\\vartheta_0=1$, respectively. Tests are conducted at the 5\\% level (black dashed line)."
#| fig-scap: "Empirical power against the dependence parameter $\\vartheta_1$ for selected $b$ and $k$."
#| fig-height: 7

p1 <- sim_results %>%
  filter(change_type %in% c("none", "jump"), d == 2, n == 2500, model == "log") %>%
  group_by(param1, n_blocks, k_frac, test_method, test_type) %>%
  summarise(power = 100 * mean(reject_H0)) %>%
  rename('n/b' = n_blocks, 'k/b' = k_frac) %>%
  ggplot(aes(x = param1, y = power, colour = test_method, shape = test_type, linetype = test_type)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 5, linetype = "dashed", colour = "black") +
  facet_grid(`k/b` ~ `n/b`, labeller = purrr::partial(label_both, sep = " = ")) +
  xlab(expression(vartheta[1])) +
  ylab("Empirical power (%)") +
  ggtitle("SL-jump") +
  scale_x_continuous(breaks = breaks_extended(n = 5)) +
  scale_y_continuous(breaks = breaks_extended(n = 4)) +
  scale_color_manual(labels = c("Drees", "Pawley"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("CM", "KS"), values = c(1, 3)) +
  scale_shape_manual(labels = c("CM", "KS"), values = 0:1) +
  theme_light() +
  labs(colour = "Test method", shape = "Test type", linetype = "Test type") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10))

p2 <- sim_results %>%
  filter(change_type %in% c("none", "linear"), d == 2, n == 2500, model == "log") %>%
  group_by(param1, n_blocks, k_frac, test_method, test_type) %>%
  summarise(power = 100 * mean(reject_H0)) %>%
  rename('n/b' = n_blocks, 'k/b' = k_frac) %>%
  ggplot(aes(x = param1, y = power, colour = test_method, shape = test_type, linetype = test_type)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 5, linetype = "dashed", colour = "black") +
  facet_grid(`k/b` ~ `n/b`, labeller = purrr::partial(label_both, sep = " = ")) +
  xlab(expression(vartheta[1])) +
  ylab("Empirical power (%)") +
  ggtitle("SL-linear") +
  scale_x_continuous(breaks = breaks_extended(n = 5)) +
  scale_y_continuous(breaks = breaks_extended(n = 4)) +
  scale_color_manual(labels = c("Drees", "Pawley"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("CM", "KS"), values = c(1, 3)) +
  scale_shape_manual(labels = c("CM", "KS"), values = 0:1) +
  theme_light() +
  labs(colour = "Test method", shape = "Test type", linetype = "Test type") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10))


p3 <- sim_results %>%
  filter(change_type %in% c("none", "jump"), d == 2, n == 2500, model == "hr") %>%
  group_by(param1, n_blocks, k_frac, test_method, test_type) %>%
  summarise(power = 100 * mean(reject_H0)) %>%
  rename('n/b' = n_blocks, 'k/b' = k_frac) %>%
  ggplot(aes(x = param1, y = power, colour = test_method, shape = test_type, linetype = test_type)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 5, linetype = "dashed", colour = "black") +
  facet_grid(`k/b` ~ `n/b`, labeller = purrr::partial(label_both, sep = " = ")) +
  xlab(expression(vartheta[1])) +
  ylab("Empirical power (%)") +
  ggtitle("HR-jump") +
  scale_x_continuous(breaks = breaks_extended(n = 5)) +
  scale_y_continuous(breaks = breaks_extended(n = 4)) +
  scale_color_manual(labels = c("Drees", "Pawley"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("CM", "KS"), values = c(1, 3)) +
  scale_shape_manual(labels = c("CM", "KS"), values = 0:1) +
  theme_light() +
  labs(colour = "Test method", shape = "Test type", linetype = "Test type") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10))

p4 <- sim_results %>%
  filter(change_type %in% c("none", "linear"), d == 2, n == 2500, model == "hr") %>%
  group_by(param1, n_blocks, k_frac, test_method, test_type) %>%
  summarise(power = 100 * mean(reject_H0)) %>%
  rename('n/b' = n_blocks, 'k/b' = k_frac) %>%
  ggplot(aes(x = param1, y = power, colour = test_method, shape = test_type, linetype = test_type)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept = 5, linetype = "dashed", colour = "black") +
  facet_grid(`k/b` ~ `n/b`, labeller = purrr::partial(label_both, sep = " = ")) +
  xlab(expression(vartheta[1])) +
  ylab("Empirical power (%)") +
  ggtitle("HR-linear") +
  scale_x_continuous(breaks = breaks_extended(n = 5)) +
  scale_y_continuous(breaks = breaks_extended(n = 4)) +
  scale_color_manual(labels = c("Drees", "Pawley"), values = c("red", "blue")) +
  scale_linetype_manual(labels = c("CM", "KS"), values = c(1, 3)) +
  scale_shape_manual(labels = c("CM", "KS"), values = 0:1) +
  theme_light() +
  labs(colour = "Test method", shape = "Test type", linetype = "Test type") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10))

ggarrange(p1, p2, p3, p4, ncol = 2, nrow = 2, common.legend = TRUE)
```


```{r}
#| label: fig-redsea-test-example-north-south
#| fig-cap: "Diagnostic plots for our test, based $b=107$ and $k=20$, applied to data from $d=5$ randomly selected northerly (top two rows) and southerly (bottom two rows) sites in the Red Sea. The interpretation of each plot is the same as in @fig-counterexample-maxlinear-pawley, except now there are $\\mathcal{D}=10$ curves, one for each component pair. The variable pairs are coloured light to dark with respect to their lexicographical ordering. For the northerly (resp. southerly) sites there is sufficient (resp. insufficient) evidence to reject the null at the 5\\% level."
#| fig-scap: "Diagnostics: our test with five northerly/southerly sites in the Red Sea."
#| fig-height: 9

redsea <- load_red_sea_temp(alpha = 2)

set.seed(1)

north_sites <- redsea$coord %>%
  mutate(loc_index = row_number()) %>%
  filter(region == "north") %>%
  slice_sample(n = 5) %>%
  pull(loc_index)
    
p1 <- redsea$X[1:1605, north_sites] %>%
  as_tibble() %>%
  test_pawley(b = 107, k = 20, return_all = TRUE) %>%
  extract2("data") %>%
  plot_test_pawley(variable_scheme = "colour")

set.seed(1)

south_sites <- redsea$coord %>%
  mutate(loc_index = row_number()) %>%
  filter(region == "south") %>%
  slice_sample(n = 5) %>%
  pull(loc_index)
    
p2 <- redsea$X[1:1605, south_sites] %>%
  as_tibble() %>%
  test_pawley(b = 107, k = 20, return_all = TRUE) %>%
  extract2("data") %>%
  plot_test_pawley(variable_scheme = "colour")

ggarrange(p1, p2, nrow = 2)
```

## Effect of the bias of the empirical TPDM {#sec-app-changing-ext-dep-bias-issue}

Since the empirical TPDM struggles to discriminate between differences in dependence strengths at weak levels (@fig-parametric-chi-tpdm-small-n), we find that the power of our test varies according to the underlying dependence strength. This phenomenon is illustrated in @fig-test-power-weak-dependence. The plots concern data generated from the SL-linear model with $d=3$. In the top plot, the dependence parameter $\gamma$ evolves linearly from $\gamma(0)=0.06$ (corresponding to $\sigma_{ij}(0)=0.998$) to $\gamma(1)=0.10$ (0.996). In the bottom plot, the corresponding values are $\gamma(0)=0.95$ (0.147) to $\gamma(1)=0.99$ (0.031). One might assume that the second dependence change is easier to detect, because the change in the TPDM is greater. However, the deficiencies of the empirical TPDM mean this is not the case. Indeed, the bottom-right sub-panels reveal that the null is only rejected for the first test. While we have not conducted a full study of the power, we expect this to replicate over repeated simulations. To address this shortcoming, one might consider employing a TPDM estimator with better finite-sample performance in weak dependence settings. Such an estimator is proposed in @sec-shrinkage-tpdm. In order to use this estimator in our test, one needs to undertake an asymptotic analysis analogous to @sec-changing-ext-dep-asymptotic-properties. We conjecture that the results will follow identically, so in effect the new estimator may simply be plugged in to our testing framework. 

```{r}
#| label: fig-test-power-weak-dependence
#| fig-cap: "Diagnostic plots for our test based on $n=5,000$ samples of SL-linear data in $d=3$ dimensions. For the interpretation of the plot, see the caption of @fig-counterexample-maxlinear-pawley. Top: a strong dependence scenario where $\\gamma(0)=0.06$ and $\\gamma(1)=0.10$. Bottom: a weak dependence scenario where $\\gamma(0)=0.95$ and $\\gamma(1)=0.99$."
#| fig-scap: "Diagnostics: our test with symmetric logistic data."
#| fig-height: 7

set.seed(1)
p1 <- sim_X_changing_dep(n = 5000, d = 3, model = "log", param0 = 1 / 0.06, param1 = 1 / 0.1, change_type = "linear") %>%
  set_colnames(paste0("X", 1:3)) %>%
  test_pawley(b = 250, k = 25, return_all = TRUE) %>%
  extract2("data") %>%
  plot_test_pawley(variable_scheme = "colour")

p2 <- sim_X_changing_dep(n = 5000, d = 3, model = "log", param0 = 1 / 0.95, param1 = 1 / 0.99, change_type = "linear") %>%
  set_colnames(paste0("X", 1:3)) %>%
  test_pawley(b = 250, k = 25, return_all = TRUE) %>%
  extract2("data") %>%
  plot_test_pawley(variable_scheme = "colour")
  
ggarrange(p1, p2, nrow = 2)
```



